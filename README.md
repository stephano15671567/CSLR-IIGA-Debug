# CSLR-IIGA-Debug ğŸ”

**Debugging and Explanation Tool for Continuous Sign Language Recognition with Intra-Inter Gloss Attention**

Este repositorio contiene scripts de debugging, visualizaciones y documentaciÃ³n completa para entender el flujo del modelo IIGA de principio a fin.

## ğŸ¯ PropÃ³sito

Explicar y debuggear cada parte del pipeline CSLR-IIGA:
- **Dataloader**: CÃ³mo se cargan y procesan los videos
- **CNN (MobileNetV2)**: ExtracciÃ³n de caracterÃ­sticas
- **Transformer (IIGA)**: AtenciÃ³n intra-glosa e inter-glosa
- **Decoder**: PredicciÃ³n final de glosas
- **MÃ©tricas**: WER, BLEU, ROUGE

## ğŸ“‹ Estructura

```
CSLR-IIGA-Debug/
â”œâ”€â”€ IIGA/                          # Scripts de debugging
â”‚   â”œâ”€â”€ train_debug.py             # Training con logs detallados
â”‚   â”œâ”€â”€ train_debug_COMPLETO.py    # â­ VERSIÃ“N MATEMÃTICA COMPLETA
â”‚   â”œâ”€â”€ attention_visualization.py # VisualizaciÃ³n de attention weights
â”‚   â”œâ”€â”€ architecture_details.py    # AnÃ¡lisis completo de arquitectura
â”‚   â”œâ”€â”€ dataloader_debug.py        # Debug del dataloader
â”‚   â”œâ”€â”€ transformer_debug.py       # Debug de capas
â”‚   â””â”€â”€ segmentation_debug.py      # Debug de segmentaciÃ³n
â”‚
â”œâ”€â”€ debug_outputs/
â”‚   â””â”€â”€ logs/                      # Logs generados (automÃ¡tico)
â”‚
â”œâ”€â”€ docs/                          # DocumentaciÃ³n
â”‚   â”œâ”€â”€ GUIA_PASO_A_PASO.md       # Tutorial completo
â”‚   â”œâ”€â”€ FAQ.md                     # Preguntas frecuentes
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # Detalles tÃ©cnicos
â”‚   â”œâ”€â”€ MATEMATICAS.md             # â­ ECUACIONES FORMALES
â”‚   â””â”€â”€ DATASETS.md                # Info de datasets
â”‚
â””â”€â”€ requirements.txt               # Dependencias Python
```

## ğŸš€ Quick Start

### 1. Clonar el repositorio

```bash
git clone https://github.com/TU_USUARIO/CSLR-IIGA-Debug.git
cd CSLR-IIGA-Debug
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Ejecutar debug del entrenamiento

```bash
cd IIGA
python train_debug.py --debug_samples 3 --num_epochs 1
```

Ver logs:
```bash
type ..\debug_outputs\logs\train_debug_*.log
```

### 4. Ejecutar debug del dataloader

```bash
python dataloader_debug.py --data_path "..\data_sample\phoenix-2014-mini" --num_samples 2
```

### 5. Ver resultados

Los logs se generan automÃ¡ticamente en `debug_outputs/logs/`

## ğŸ“š Scripts Disponibles

## ğŸ”§ Scripts Disponibles

### `train_debug.py` - Training BÃ¡sico
Muestra el flujo completo con logs detallados:
```bash
python train_debug.py --debug_samples 3 --num_epochs 1
```

**Output:**
- Procesamiento de datos paso a paso
- CNN embedding
- IIGA transformer
- Decoder y pÃ©rdida
- MÃ©tricas (WER, BLEU, ROUGE)

---

### â­ `train_debug_COMPLETO.py` - VersiÃ³n MatemÃ¡tica Completa
Muestra TODO el flujo con ecuaciones matemÃ¡ticas formales:
```bash
python train_debug_COMPLETO.py --debug_samples 2 --num_epochs 1
```

**Output adicional:**
- **Ecuaciones matemÃ¡ticas** paso a paso (Positional Encoding, Attention, LayerNorm, etc.)
- **Dimensiones exactas** en cada capa
- **CÃ¡lculos de attention** detallados (Q, K, V, scores, softmax)
- **CTC Loss** con explicaciÃ³n de forward-backward
- **Conteo de parÃ¡metros** por mÃ³dulo
- **AnÃ¡lisis de complejidad** (FLOPs, memoria)
- **VisualizaciÃ³n de matrices** de attention

---

### `attention_visualization.py` - AnÃ¡lisis de Attention Weights
Visualiza y analiza los pesos de atenciÃ³n:
```bash
python attention_visualization.py --num_samples 2
```

**Output:**
- Matrices de attention por cabeza (8 cabezas)
- Patrones Intra-Gloss (ventana local)
- Patrones Inter-Gloss (atenciÃ³n global)
- EstadÃ­sticas: self-attention, entropy, concentraciÃ³n
- InterpretaciÃ³n de quÃ© frames atienden a quÃ© frames

---

### `architecture_details.py` - AnÃ¡lisis de Arquitectura
Desglose completo de la arquitectura:
```bash
python architecture_details.py
```

**Output:**
- Todas las capas con dimensiones exactas
- ParÃ¡metros por mÃ³dulo (MHA, FFN, Decoder)
- Complejidad computacional (FLOPs por operaciÃ³n)
- Memoria requerida (parÃ¡metros + activaciones)
- ComparaciÃ³n con otras arquitecturas (ResNet+LSTM, ViT)

---

### `dataloader_debug.py` - Debug del Dataloader
Muestra cÃ³mo se cargan y procesan los datos:
```bash
python dataloader_debug.py
```

**Output:**
- Lectura de CSV
- SelecciÃ³n de 12 frames uniformes
- Rescalado a 224Ã—224
- ConversiÃ³n de glosas a Ã­ndices

---

### `transformer_debug.py` - Debug del Transformer
Muestra cada capa del transformer:
```bash
python transformer_debug.py
```

**Output:**
- Positional Encoding
- Multi-Head Attention
- Layer Normalization
- Feed-Forward Network

---

### `segmentation_debug.py` - Debug de SegmentaciÃ³n
Muestra extracciÃ³n de background:
```bash
python segmentation_debug.py
```

**Output:**
- DetecciÃ³n con MediaPipe Holistic
- AplicaciÃ³n de mÃ¡scara (threshold 0.5)
- Resize de ROI

## ğŸ“Š Ejemplos de Output

### Train Debug Log

```
[PASO 1] VERIFICANDO RUTAS Y DATOS
  âœ“ Dataset encontrado
  âœ“ Total de videos: 4000

[PASO 2] CARGANDO ANOTACIONES
  [0] S0001 â†’ "HOLA BANCO DINERO"
  [1] S0002 â†’ "BUENOS DÃAS"

[PASO 3] PROCESANDO DATOS
  - Frames encontrados: 45
  - Ãndices seleccionados: [0, 4, 8, 12, ...]
  - Shape de frames: (12, 3, 224, 224)

[PASO 4] CNN EMBEDDING
  Input: (1, 12, 3, 224, 224)
  Output: (1, 12, 1280)

[PASO 5] IIGA TRANSFORMER
  Output: (1, 12, 1280)

[PASO 6] DECODER
  Output: (1, 12, 1232)

[PASO 7] LOSS & MÃ‰TRICAS
  Loss: 2.345
  WER: 0.333
```

## ğŸ“– DocumentaciÃ³n Completa

1. **[GUIA_PASO_A_PASO.md](./docs/GUIA_PASO_A_PASO.md)**: Tutorial completo para principiantes
2. **[MATEMATICAS.md](./docs/MATEMATICAS.md)**: â­ **TODAS las ecuaciones matemÃ¡ticas formales**
   - NotaciÃ³n completa
   - Ecuaciones de CNN (MobileNetV2)
   - Positional Encoding (sinusoidal)
   - Multi-Head Attention (Q, K, V)
   - Layer Normalization
   - Feed-Forward Network
   - CTC Loss (forward-backward algorithm)
   - MÃ©tricas (WER, BLEU, ROUGE)
   - OptimizaciÃ³n (AdamW)
   - Complejidad computacional
3. **[ARCHITECTURE.md](./docs/ARCHITECTURE.md)**: Detalles tÃ©cnicos de arquitectura
4. **[DATASETS.md](./docs/DATASETS.md)**: InformaciÃ³n sobre PHOENIX-2014 y otros datasets
5. **[FAQ.md](./docs/FAQ.md)**: Preguntas frecuentes

## ğŸ” Conceptos Explicados

### 1. **Ventana de 12 Frames**
- DuraciÃ³n tÃ­pica de una seÃ±a
- 12 frames Ã· 25 fps = 0.48 segundos
- ConfiguraciÃ³n del paper original

### 2. **Intra-Gloss Attention**
- Relaciones DENTRO de una seÃ±a
- Â¿CÃ³mo evoluciona el movimiento?
- Ventana deslizante de 12 frames

### 3. **Inter-Gloss Attention**
- Relaciones ENTRE signos diferentes
- Â¿CÃ³mo se transiciona?
- Conexiones entre ventanas

### 4. **CNN vs Transformer**
- **CNN**: Extrae caracterÃ­sticas visuales (1280 dims)
- **Transformer**: Modela relaciones temporales
- **Juntos**: Capturan estÃ¡tica + dinÃ¡mica

## ğŸ“ˆ Metricas

El modelo calcula:
- **WER** (Word Error Rate): Errores por palabra
- **BLEU-1 a BLEU-4**: PrecisiÃ³n de n-gramas
- **ROUGE-L**: Recall de secuencias

## ğŸ“ Uso Educativo

Este repositorio es ideal para:
- âœ… Entender el flujo completo del modelo
- âœ… Debuggear problemas de datos
- âœ… Explicar a profesores/colegas
- âœ… Modificar y experimentar
- âœ… Crear visualizaciones propias

## ğŸ“ Logs Generados

Cada ejecuciÃ³n genera un log Ãºnico:
```
debug_outputs/logs/train_debug_20260121_143022.log
```

Logs incluyen:
- Timestamps
- Niveles de severidad (INFO, WARNING, ERROR)
- Shapes de tensores
- Valores de mÃ©tricas

## ğŸ› ï¸ Requerimientos

```
torch>=2.0.0
torchvision>=0.15.0
mediapipe>=0.10.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
scikit-image>=0.20.0
jiwer>=3.0.0
sacrebleu>=2.3.0
rouge-score>=0.1.2
tensorflow>=2.13.0
```

## ğŸ”„ Flujo Visual

```
VIDEO INPUT (384Ã—288Ã—3)
    â†“
[DATALOADER] â†’ 12 frames rescaleados
    â†“ (1, 12, 3, 224, 224)
[CNN] â†’ MobileNetV2 extrae features
    â†“ (1, 12, 1280)
[IIGA TRANSFORMER]
  â”œâ”€ Intra-Gloss Attention
  â”œâ”€ Inter-Gloss Attention
  â””â”€ Feed Forward
    â†“ (1, 12, 1280)
[DECODER] â†’ Predice glosas
    â†“ (1, 12, 1232)
PREDICCIÃ“N: "HOLA BANCO DINERO"
```

## ğŸ“ Soporte

Para preguntas o problemas:
1. Revisa [FAQ.md](./docs/FAQ.md)
2. Crea un Issue en GitHub
3. Consulta la [GuÃ­a Completa](./docs/GUIA_PASO_A_PASO.md)

## ğŸ“„ Licencia

MIT License - Ver [LICENSE](./LICENSE) para detalles

## ğŸ™ CrÃ©ditos

Basado en:
- **Paper**: "Continuous Sign Language Recognition Using Intra-Inter Gloss Attention"
- **Autores**: Ranjbar & Taheri (2024)
- **Dataset**: RWTH-PHOENIX-2014

## ğŸ“Œ Ãšltima ActualizaciÃ³n

21/01/2026

---

**Â¡Esperamos que este repositorio te ayude a entender y explicar el modelo IIGA!** ğŸš€
