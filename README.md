# CSLR-IIGA-Debug ğŸ”

**Debugging and Explanation Tool for Continuous Sign Language Recognition with Intra-Inter Gloss Attention**

Este repositorio contiene scripts de debugging, visualizaciones y documentaciÃ³n completa para entender el flujo del modelo IIGA de principio a fin.

## ğŸ¯ PropÃ³sito

Explicar y debuggear cada parte del pipeline CSLR-IIGA:
- **Dataloader**: CÃ³mo se cargan y procesan los videos
- **CNN (MobileNetV2)**: ExtracciÃ³n de caracterÃ­sticas
- **Transformer (IIGA)**: AtenciÃ³n intra-glosa e inter-glosa
- **Decoder**: PredicciÃ³n final de glosas
- **MÃ©tricas**: WER, BLEU, ROUGE

## ğŸ“‹ Estructura

```
CSLR-IIGA-Debug/
â”œâ”€â”€ IIGA/                          # Scripts de debugging
â”‚   â”œâ”€â”€ train_debug.py             # Debug del flujo completo
â”‚   â”œâ”€â”€ dataloader_debug.py        # Debug del dataloader
â”‚   â”œâ”€â”€ transformer_debug.py       # Debug de capas
â”‚   â”œâ”€â”€ segmentation_debug.py      # Debug de segmentaciÃ³n
â”‚   â””â”€â”€ tools/                     # Utilidades
â”‚
â”œâ”€â”€ data_sample/                   # Dataset pequeÃ±o para testing
â”‚   â”œâ”€â”€ phoenix-2014-mini/         # 5-10 videos de ejemplo
â”‚   â”œâ”€â”€ segmentation_mini/         # ROI pre-generados
â”‚   â””â”€â”€ phoenix2014.v3.train.csv   # CSV mini (primeras lÃ­neas)
â”‚
â”œâ”€â”€ debug_outputs/
â”‚   â”œâ”€â”€ logs/                      # Logs generados (automÃ¡tico)
â”‚   â””â”€â”€ visualizations/            # GrÃ¡ficos generados (automÃ¡tico)
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks explicativos
â”‚   â”œâ”€â”€ 01_flujo_completo.ipynb
â”‚   â”œâ”€â”€ 02_dataloader.ipynb
â”‚   â””â”€â”€ 03_transformer.ipynb
â”‚
â”œâ”€â”€ docs/                          # DocumentaciÃ³n
â”‚   â”œâ”€â”€ GUIA_PASO_A_PASO.md
â”‚   â”œâ”€â”€ FAQ.md
â”‚   â””â”€â”€ ARCHITECTURE.md
â”‚
â””â”€â”€ requirements.txt               # Dependencias Python
```

## ğŸš€ Quick Start

### 1. Clonar el repositorio

```bash
git clone https://github.com/TU_USUARIO/CSLR-IIGA-Debug.git
cd CSLR-IIGA-Debug
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. Ejecutar debug del entrenamiento

```bash
cd IIGA
python train_debug.py --debug_samples 3 --num_epochs 1
```

Ver logs:
```bash
type ..\debug_outputs\logs\train_debug_*.log
```

### 4. Ejecutar debug del dataloader

```bash
python dataloader_debug.py --data_path "..\data_sample\phoenix-2014-mini" --num_samples 2
```

### 5. Ver resultados

Los logs se generan automÃ¡ticamente en `debug_outputs/logs/`

## ğŸ“š Scripts Disponibles

### `train_debug.py`
Muestra el flujo completo del entrenamiento con logs detallados:
```bash
python train_debug.py \
    --debug_samples 3 \
    --batch_size 1 \
    --num_epochs 1 \
    --local_window 12
```

**Output:**
- VerificaciÃ³n de rutas
- Carga de anotaciones
- Procesamiento de datos
- CNN embedding
- IIGA transformer
- Decoder
- Loss & MÃ©tricas

### `dataloader_debug.py`
Muestra cÃ³mo se cargan y procesan los datos:
```bash
python dataloader_debug.py \
    --data_path "./data_sample/phoenix-2014-mini" \
    --num_samples 2 \
    --batch_size 1
```

**Output:**
- Lectura de CSV
- Lectura de frames
- SelecciÃ³n de 12 frames
- Rescalado a 224Ã—224
- ConversiÃ³n de glosas a Ã­ndices

### `transformer_debug.py`
Muestra cada capa del transformer:
```bash
python transformer_debug.py \
    --hidden_size 1280 \
    --num_heads 10 \
    --window_size 12
```

### `segmentation_debug.py`
Muestra cÃ³mo se extrae la segmentaciÃ³n:
```bash
python segmentation_debug.py \
    --image_path "./data_sample/sample_frame.png"
```

## ğŸ“Š Ejemplos de Output

### Train Debug Log

```
[PASO 1] VERIFICANDO RUTAS Y DATOS
  âœ“ Dataset encontrado
  âœ“ Total de videos: 4000

[PASO 2] CARGANDO ANOTACIONES
  [0] S0001 â†’ "HOLA BANCO DINERO"
  [1] S0002 â†’ "BUENOS DÃAS"

[PASO 3] PROCESANDO DATOS
  - Frames encontrados: 45
  - Ãndices seleccionados: [0, 4, 8, 12, ...]
  - Shape de frames: (12, 3, 224, 224)

[PASO 4] CNN EMBEDDING
  Input: (1, 12, 3, 224, 224)
  Output: (1, 12, 1280)

[PASO 5] IIGA TRANSFORMER
  Output: (1, 12, 1280)

[PASO 6] DECODER
  Output: (1, 12, 1232)

[PASO 7] LOSS & MÃ‰TRICAS
  Loss: 2.345
  WER: 0.333
```

## ğŸ“– DocumentaciÃ³n

- **[GUIA_PASO_A_PASO.md](./docs/GUIA_PASO_A_PASO.md)**: GuÃ­a completa paso a paso
- **[ARCHITECTURE.md](./docs/ARCHITECTURE.md)**: ExplicaciÃ³n de la arquitectura IIGA
- **[FAQ.md](./docs/FAQ.md)**: Preguntas frecuentes

## ğŸ” Conceptos Explicados

### 1. **Ventana de 12 Frames**
- DuraciÃ³n tÃ­pica de una seÃ±a
- 12 frames Ã· 25 fps = 0.48 segundos
- ConfiguraciÃ³n del paper original

### 2. **Intra-Gloss Attention**
- Relaciones DENTRO de una seÃ±a
- Â¿CÃ³mo evoluciona el movimiento?
- Ventana deslizante de 12 frames

### 3. **Inter-Gloss Attention**
- Relaciones ENTRE signos diferentes
- Â¿CÃ³mo se transiciona?
- Conexiones entre ventanas

### 4. **CNN vs Transformer**
- **CNN**: Extrae caracterÃ­sticas visuales (1280 dims)
- **Transformer**: Modela relaciones temporales
- **Juntos**: Capturan estÃ¡tica + dinÃ¡mica

## ğŸ“ˆ Metricas

El modelo calcula:
- **WER** (Word Error Rate): Errores por palabra
- **BLEU-1 a BLEU-4**: PrecisiÃ³n de n-gramas
- **ROUGE-L**: Recall de secuencias

## ğŸ“ Uso Educativo

Este repositorio es ideal para:
- âœ… Entender el flujo completo del modelo
- âœ… Debuggear problemas de datos
- âœ… Explicar a profesores/colegas
- âœ… Modificar y experimentar
- âœ… Crear visualizaciones propias

## ğŸ“ Logs Generados

Cada ejecuciÃ³n genera un log Ãºnico:
```
debug_outputs/logs/train_debug_20260121_143022.log
```

Logs incluyen:
- Timestamps
- Niveles de severidad (INFO, WARNING, ERROR)
- Shapes de tensores
- Valores de mÃ©tricas

## ğŸ› ï¸ Requerimientos

```
torch>=2.0.0
torchvision>=0.15.0
mediapipe>=0.10.0
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
scikit-image>=0.20.0
jiwer>=3.0.0
sacrebleu>=2.3.0
rouge-score>=0.1.2
tensorflow>=2.13.0
```

## ğŸ”„ Flujo Visual

```
VIDEO INPUT (384Ã—288Ã—3)
    â†“
[DATALOADER] â†’ 12 frames rescaleados
    â†“ (1, 12, 3, 224, 224)
[CNN] â†’ MobileNetV2 extrae features
    â†“ (1, 12, 1280)
[IIGA TRANSFORMER]
  â”œâ”€ Intra-Gloss Attention
  â”œâ”€ Inter-Gloss Attention
  â””â”€ Feed Forward
    â†“ (1, 12, 1280)
[DECODER] â†’ Predice glosas
    â†“ (1, 12, 1232)
PREDICCIÃ“N: "HOLA BANCO DINERO"
```

## ğŸ“ Soporte

Para preguntas o problemas:
1. Revisa [FAQ.md](./docs/FAQ.md)
2. Crea un Issue en GitHub
3. Consulta la [GuÃ­a Completa](./docs/GUIA_PASO_A_PASO.md)

## ğŸ“„ Licencia

MIT License - Ver [LICENSE](./LICENSE) para detalles

## ğŸ™ CrÃ©ditos

Basado en:
- **Paper**: "Continuous Sign Language Recognition Using Intra-Inter Gloss Attention"
- **Autores**: Ranjbar & Taheri (2024)
- **Dataset**: RWTH-PHOENIX-2014

## ğŸ“Œ Ãšltima ActualizaciÃ³n

21/01/2026

---

**Â¡Esperamos que este repositorio te ayude a entender y explicar el modelo IIGA!** ğŸš€
